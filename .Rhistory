# knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
#Just some tests on the new sub dataset
mean(By_State$stbcp)
knitr::opts_chunk$set(echo = FALSE)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
# knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
=======
knitr::opts_chunk$set(echo = TRUE)
ggplot(fp, aes(x = regions, y = frequency(regions), color=body_camera)) + geom_bar(stat = "identity")+ labs(x = "State", y="Number of Incidents", title = "Regional Police Shootings Colored by Body Camera Proportions")
knitr::opts_chunk$set(echo = TRUE)
>>>>>>> Stashed changes
#Calling Packages
library(dplyr)
library(ggplot2)
fp1<- data.frame(read.csv("FPS22.csv"))
#Cleaning null values from dataset
fp <- na.omit(fp1) # Method 1 - Remove NA
#Getting row count and latest incident
<<<<<<< Updated upstream
print("Number of observations:")
nrow(fp)
head(fp, 1)
=======
nrow(fp)
max(fp$date)
>>>>>>> Stashed changes
#test stats
str(fp)
mean(fp$age, na.rm= TRUE)
median(fp$age)
<<<<<<< Updated upstream
ggplot(fp, aes(x=race,fill=race, color=race)) + geom_histogram(stat="count") + labs(x = "Race: Unknown, Asian, Black, Hispanic, Native, Other, White", y="Number of Incidents", title = "Race Frequency Histogram")
ggplot(fp, aes(x=gender, fill=gender, color=gender)) + geom_histogram(stat="count") + labs(x = "Gender", y="Number of Incidents", title = "Gender Frequency Histogram")
ggplot(fp, aes(x= manner_of_death, fill=manner_of_death, color=manner_of_death)) + geom_histogram(stat="count") + labs(x = "Manner of Death", y="Number of Incidents", title = "Manner of Death Frequency Histogram")
ggplot(fp, aes(x=threat_level, fill=threat_level, color=threat_level)) + geom_histogram(stat="count") + labs(x = "Threat Level", y="Number of Incidents", title = "Threat Level Frequency Histogram")
ggplot(fp, aes(x=state, fill=state, color=state)) + geom_histogram(stat="count") + labs(x = "State", y="Number of Incidents", title = "State Frequency Histogram")
#Initial Creation of Regional Subgroups and tests that they cover everything. DO NOT MODIFY. THIS WAS SUPER HARD TO MAKE.
NW <- subset(fp, state=="CA"| state=="WA" | state=="OR" | state== "NV"| state=="ID"| state=="UT"|state=="MT"|state=="CO"| state=="WY"| state=="AK")
print("Incidents in NW:")
nrow(NW)
SW <- subset(fp, state== "NM"| state=="AZ"| state== "TX"| state=="OK"| state== "HI")
print("Incidents in SW:")
nrow(SW)
MW <- subset(fp, state== "IL"| state=="WI"| state=="IN"| state=="MI"| state== "MN"| state== "MO"| state== "IA"| state=="KS"| state=="ND"| state== "SD"| state=="NE"| state=="OH")
print("Incidents in MW:")
nrow(MW)
SE <- subset(fp, state == "GA"| state=="AL"| state== "MS"| state=="LA"| state=="TN"| state=="NC"| state=="SC"| state=="FL"| state== "AR"|state=="WV"| state=="DC"| state=="VA"| state=="KY"| state=="DE")
print("Incidents in SE:")
nrow(SE)
NE <- subset(fp, state=="NY"| state== "MD"| state=="RI"| state== "VT"| state=="PA"| state=="ME"| state== "NH"| state=="NJ"| state=="CT"| state=="MA")
print("Incidents in NE:")
nrow(NE)
=======
#First 7 names Printed
count=1
for (i in fp$name){
if (i== "Brock Nichols"){
break}
else {
print (i)}
print(count)
count= count+1
}
#Initial Creation of Regional Subgroups and tests that they cover everything. DO NOT MODIFY. THIS WAS SUPER HARD TO MAKE.
NW <- subset(fp, state=="CA"| state=="WA" | state=="OR" | state== "NV"| state=="ID"| state=="UT"|state=="MT"|state=="CO"| state=="WY"| state=="AK")
nrow(NW)
SW <- subset(fp, state== "NM"| state=="AZ"| state== "TX"| state=="OK"| state== "HI")
nrow(SW)
MW <- subset(fp, state== "IL"| state=="WI"| state=="IN"| state=="MI"| state== "MN"| state== "MO"| state== "IA"| state=="KS"| state=="ND"| state== "SD"| state=="NE"| state=="OH")
nrow(MW)
SE <- subset(fp, state == "GA"| state=="AL"| state== "MS"| state=="LA"| state=="TN"| state=="NC"| state=="SC"| state=="FL"| state== "AR"|state=="WV"| state=="DC"| state=="VA"| state=="KY"| state=="DE")
nrow(SE)
NE <- subset(fp, state=="NY"| state== "MD"| state=="RI"| state== "VT"| state=="PA"| state=="ME"| state== "NH"| state=="NJ"| state=="CT"| state=="MA")
nrow(NE)
(nrow(NE)+nrow(SE) +nrow(MW) +nrow(SW) + nrow(NW))
nrow(fp)
>>>>>>> Stashed changes
#Implementation of the subgroups as a new factor called "regions". PLEASE PLEASE DO NOT MODIFY. THIS TOOK FOREVER
fp$regions <- as.factor(ifelse(( fp$state=="CA"| fp$state=="WA" | fp$state=="OR" | fp$state== "NV"| fp$state=="ID"| fp$state=="UT"|fp$state=="MT"|fp$state=="CO"| fp$state=="WY"| fp$state=="AK"), 'NW',
ifelse((fp$state== "NM"| fp$state=="AZ"| fp$state== "TX"| fp$state=="OK"| fp$state== "HI"), 'SW',
ifelse((fp$state== "IL"| fp$state=="WI"| fp$state=="IN"| fp$state=="MI"| fp$state== "MN"| fp$state== "MO"| fp$state== "IA"| fp$state=="KS"| fp$state=="ND"| fp$state== "SD"| fp$state=="NE"| fp$state=="OH"), 'MW',
ifelse(( fp$state=="NY"| fp$state== "MD"| fp$state=="RI"| fp$state== "VT"| fp$state=="PA"| fp$state=="ME"| fp$state== "NH"| fp$state=="NJ"| fp$state=="CT"| fp$state=="MA"), 'NE', 'SE')))))
<<<<<<< Updated upstream
#Defining 2 new datasets. These show all the variables (with some modification) by state. PLEASE DO NOT MODIFY. THIS WAS HARD AS HELL.
=======
#Defining 2 new factors called stbcp and rgbcp. These show the proportions of body cameras being on per state and per region respectively. PLEASE DO NOT MODIFY. THIS WAS HARD AS HELL.
>>>>>>> Stashed changes
#Still working on it
sfp <- fp %>%
group_by(state) %>%
mutate(stbcp =  sum(body_camera==1)/n())
<<<<<<< Updated upstream
#This is a numeric proportion of the Men by state
sfp <- sfp %>%
group_by(state) %>%
mutate(gen.p =  sum(gender=="M")/n())
#This is a numeric proportion of sings_of_mental_illness by state
sfp <- sfp %>%
group_by(state) %>%
mutate(smi.p =  sum(signs_of_mental_illness==TRUE)/n())
#This is a numeric proportion of fleeing victims by state
sfp <- sfp %>%
group_by(state) %>%
mutate(flee.p =  sum(flee=="fleeing")/n())
#This is a numeric proportion of attackers by state
sfp <- sfp %>%
group_by(state) %>%
mutate(att.p =  sum(threat_level== "attack")/n())
#This is a numeric proportion of armed victims by state
sfp <- sfp %>%
group_by(state) %>%
mutate(armed.p =  sum(armed != "unarmed")/n())
#This is a numeric proportion of suspects being shot (as opposed to tasered) by state
sfp <- sfp %>%
group_by(state) %>%
mutate(MoD.p =  sum(manner_of_death == "shot")/n())
#This is the average age by state
sfp <- sfp %>%
group_by(state) %>%
mutate(age.avg =  sum(age)/n())
#This is variable is for later analysis (maybe for the final) and is the proportion of non-white victims by state
sfp <- sfp %>%
group_by(state) %>%
mutate(Non_White_prop =  sum(race != "W")/n())
#This line just drops all non grouped by state data from this version of the dataframe
By_State <- subset(sfp, select= -c(name, id, age, latitude, longitude, city, manner_of_death, gender, armed, race, signs_of_mental_illness, flee, threat_level, body_camera, date, is_geocoding_exact))
rfp <- fp %>%
group_by(regions) %>%
mutate(rgbcp =  sum(body_camera==TRUE)/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(gen.p =  sum(gender=="M")/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(smi.p =  sum(signs_of_mental_illness==TRUE)/n())
rfp <- rfp %>%
group_by(regions) %>%
mutate(flee.p =  sum(flee=="fleeing")/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(att.p =  sum(threat_level== "attack")/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(armed.p =  sum(armed != "unarmed")/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(MoD.p =  sum(manner_of_death == "shot")/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(age.avg =  sum(age)/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(Non_White_prop =  sum(race != "W")/n())
By_Region <- subset(sfp, select= -c(name, id, age, latitude, longitude, city, manner_of_death, gender, armed, race, signs_of_mental_illness, flee, threat_level, body_camera, regions, date, is_geocoding_exact))
#Just some tests on the new sub dataset
mean(By_State$stbcp)
#a bar graph showing number of fatal police shootings AND proportions of body cameras being on by region (too many states to show on a bar graph like this)
ggplot(fp, aes(x = regions, y = frequency(regions), color=body_camera)) + geom_bar(stat = "identity")+ labs(x = "State", y="Number of Incidents", title = "Regional Police Shootings Colored by Body Camera Proportions")
#Normality check of proportions of body cameras being on by state
qqnorm(By_State$stbcp)
#Seems Normal
#Scatter Plot of Body Camera Proportion by State
ggplot(By_State, aes(x=state, y= stbcp, label=state)) + geom_point(shape=6, color="violet")+ labs(x = "State", y="Body Camera Proportion", title = "Body Camera On Proportion By US State") + geom_text(hjust=1, vjust=-0.6)
#This is kind of a mess so lets try grouping by regions on the next graph
#ggplot(By_Region, aes(x=regions, y= rgbcp, label=regions)) + geom_point(shape=8, color="navy")+ labs(x = "Region", y="Body Camera Proportion", title = "Body Camera On Proportion #By US Region") +  geom_text(hjust=1, vjust=-0.6)
summary(By_State)
#Some statistical testing that I need to tinker more with next week
itwo.way <- aov(stbcp ~ ((age.avg * Non_White_prop * gen.p) + (smi.p * flee.p * MoD.p * att.p * armed.p)), data=sfp)
summary(itwo.way)
# Use sfp to call dataset grouped by states, call rfp dataset grouped by regions, and fp
mean(rfp$rgbcp)
head(By_State)
test<- By_State
cat3 <- test %>% mutate(proportion=cut(stbcp, breaks=c(0, 0.10, 0.2, 0.3, Inf),labels = c("low", "medium", "high", "very high")))
summary(cat3$stbcp)
cat3$state <- as.factor(cat3$state)
cat3$stbcp <- as.factor(cat3$stbcp)
contable= table(cat3$state, cat3$stbcp)
#print(contable)
chisq.test(contable)
#Just some tests on the new sub dataset
str(By_State)
str(By_Region)
#Just some tests on the new sub dataset
summary(By_State)
summary(By_Region)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
police<- data.frame(read.csv("FPS22.csv"))
police <- (police %>% filter(race != ''))
police <- (police %>% filter(gender != ''))
str(police)
ncol(police)
nrow(police)
summary(police$date)
##
class(police$date)
police$date <- as.Date(police$date, "%m/%d/%Y")
police$date <- as.Date(police$date, "%m/%d/%Y")
police$month <- format(police$date, format = "%m")
police$year <- format(police$date, format = "%Y")
police$month <- format(police$date, format = "%m")
police$year <- format(police$date, format = "%Y")
library(plotly)
mean(By_State$stbcp)
test<- By_State
cat3 <- test %>% mutate(proportion=cut(stbcp, breaks=c(0, 0.10, 0.2, 0.3, Inf),labels = c("low", "medium", "high", "very high")))
summary(cat3$stbcp)
cat3$state <- as.factor(cat3$state)
cat3$stbcp <- as.factor(cat3$stbcp)
contable= table(cat3$state, cat3$stbcp)
#print(contable)
chisq.test(contable)
#Just some tests on the new sub dataset
print("By_State:")
summary(By_State)
print("By Region:")
summary(By_Region)
knitr::opts_chunk$set(echo = FALSE)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
# knitr::opts_chunk$set(warning = F, results = "hide", message = F)
=======
rfp <- fp %>%
group_by(regions) %>%
mutate(rgbcp =  sum(body_camera==1)/n())
#So Now we Have two sub datasets: sfp has the stbcp column that shows each states percentage of body cameras being on, and rfp which does the same but for regions
#Just some tests on the new sub dataset
mean(sfp$stbcp)
head(sfp)
#a bar graph showing number of fatal police shootings AND proportions of body cameras being on by region (too many states to show on a bar graph like this)
ggplot(fp, aes(x = regions, y = frequency(regions), color=body_camera)) + geom_bar(stat = "identity")+ labs(x = "State", y="Number of Incidents", title = "Regional Police Shootings Colored by Body Camera Proportions")
#Normality check of proportions of body cameras being on by state
qqnorm(sfp$stbcp)
#Seems Normal
#Scatter Plot of Body Camera Proportion by State
ggplot(sfp, aes(x=state, y= stbcp, label=state)) + geom_point(shape=6, color="violet")+ labs(x = "State", y="Body Camera Proportion", title = "Body Camera On Proportion By US State") + geom_text(hjust=1, vjust=-0.6)
#This is kind of a mess so lets try grouping by regions on the next graph
ggplot(rfp, aes(x=regions, y= rgbcp, label=regions)) + geom_point(shape=8, color="navy")+ labs(x = "Region", y="Body Camera Proportion", title = "Body Camera On Proportion By US Region") +  geom_text(hjust=1, vjust=-0.6)
#Some statistical testing that I need to tinker more with next week
anova(lm( stbcp~state , sfp))
# Use sfp to call dataset grouped by states, call rfp dataset grouped by regions, and fp
mean(rfp$rgbcp)
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course.
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
# Once installed, load the library.
#tinytex::install_tinytex()
library(ezids)
library(plot3D)
library(tinytex)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
results = "hide"
)
>>>>>>> Stashed changes
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
<<<<<<< Updated upstream
knitr::opts_chunk$set(echo = FALSE)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
# knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
#Calling Packages
library(dplyr)
library(ggplot2)
fp1<- data.frame(read.csv("FPS22.csv"))
#Cleaning null values from dataset
fp <- na.omit(fp1) # Method 1 - Remove NA
#Getting row count and latest incident
print("Number of observations:")
nrow(fp)
head(fp, 1)
#test stats
str(fp)
mean(fp$age, na.rm= TRUE)
median(fp$age)
ggplot(fp, aes(x=race,fill=race, color=race)) + geom_histogram(stat="count") + labs(x = "Race: Unknown, Asian, Black, Hispanic, Native, Other, White", y="Number of Incidents", title = "Race Frequency Histogram")
ggplot(fp, aes(x=gender, fill=gender, color=gender)) + geom_histogram(stat="count") + labs(x = "Gender", y="Number of Incidents", title = "Gender Frequency Histogram")
ggplot(fp, aes(x= manner_of_death, fill=manner_of_death, color=manner_of_death)) + geom_histogram(stat="count") + labs(x = "Manner of Death", y="Number of Incidents", title = "Manner of Death Frequency Histogram")
ggplot(fp, aes(x=threat_level, fill=threat_level, color=threat_level)) + geom_histogram(stat="count") + labs(x = "Threat Level", y="Number of Incidents", title = "Threat Level Frequency Histogram")
ggplot(fp, aes(x=state, fill=state, color=state)) + geom_histogram(stat="count") + labs(x = "State", y="Number of Incidents", title = "State Frequency Histogram")
#Initial Creation of Regional Subgroups and tests that they cover everything. DO NOT MODIFY. THIS WAS SUPER HARD TO MAKE.
NW <- subset(fp, state=="CA"| state=="WA" | state=="OR" | state== "NV"| state=="ID"| state=="UT"|state=="MT"|state=="CO"| state=="WY"| state=="AK")
print("Incidents in NW:")
nrow(NW)
SW <- subset(fp, state== "NM"| state=="AZ"| state== "TX"| state=="OK"| state== "HI")
print("Incidents in SW:")
nrow(SW)
MW <- subset(fp, state== "IL"| state=="WI"| state=="IN"| state=="MI"| state== "MN"| state== "MO"| state== "IA"| state=="KS"| state=="ND"| state== "SD"| state=="NE"| state=="OH")
print("Incidents in MW:")
nrow(MW)
SE <- subset(fp, state == "GA"| state=="AL"| state== "MS"| state=="LA"| state=="TN"| state=="NC"| state=="SC"| state=="FL"| state== "AR"|state=="WV"| state=="DC"| state=="VA"| state=="KY"| state=="DE")
print("Incidents in SE:")
nrow(SE)
NE <- subset(fp, state=="NY"| state== "MD"| state=="RI"| state== "VT"| state=="PA"| state=="ME"| state== "NH"| state=="NJ"| state=="CT"| state=="MA")
print("Incidents in NE:")
nrow(NE)
#Implementation of the subgroups as a new factor called "regions". PLEASE PLEASE DO NOT MODIFY. THIS TOOK FOREVER
fp$regions <- as.factor(ifelse(( fp$state=="CA"| fp$state=="WA" | fp$state=="OR" | fp$state== "NV"| fp$state=="ID"| fp$state=="UT"|fp$state=="MT"|fp$state=="CO"| fp$state=="WY"| fp$state=="AK"), 'NW',
ifelse((fp$state== "NM"| fp$state=="AZ"| fp$state== "TX"| fp$state=="OK"| fp$state== "HI"), 'SW',
ifelse((fp$state== "IL"| fp$state=="WI"| fp$state=="IN"| fp$state=="MI"| fp$state== "MN"| fp$state== "MO"| fp$state== "IA"| fp$state=="KS"| fp$state=="ND"| fp$state== "SD"| fp$state=="NE"| fp$state=="OH"), 'MW',
ifelse(( fp$state=="NY"| fp$state== "MD"| fp$state=="RI"| fp$state== "VT"| fp$state=="PA"| fp$state=="ME"| fp$state== "NH"| fp$state=="NJ"| fp$state=="CT"| fp$state=="MA"), 'NE', 'SE')))))
#Defining 2 new datasets. These show all the variables (with some modification) by state. PLEASE DO NOT MODIFY. THIS WAS HARD AS HELL.
#Still working on it
sfp <- fp %>%
group_by(state) %>%
mutate(stbcp =  sum(body_camera==1)/n())
#This is a numeric proportion of the Men by state
sfp <- sfp %>%
group_by(state) %>%
mutate(gen.p =  sum(gender=="M")/n())
#This is a numeric proportion of sings_of_mental_illness by state
sfp <- sfp %>%
group_by(state) %>%
mutate(smi.p =  sum(signs_of_mental_illness==TRUE)/n())
#This is a numeric proportion of fleeing victims by state
sfp <- sfp %>%
group_by(state) %>%
mutate(flee.p =  sum(flee=="fleeing")/n())
#This is a numeric proportion of attackers by state
sfp <- sfp %>%
group_by(state) %>%
mutate(att.p =  sum(threat_level== "attack")/n())
#This is a numeric proportion of armed victims by state
sfp <- sfp %>%
group_by(state) %>%
mutate(armed.p =  sum(armed != "unarmed")/n())
#This is a numeric proportion of suspects being shot (as opposed to tasered) by state
sfp <- sfp %>%
group_by(state) %>%
mutate(MoD.p =  sum(manner_of_death == "shot")/n())
#This is the average age by state
sfp <- sfp %>%
group_by(state) %>%
mutate(age.avg =  sum(age)/n())
#This is variable is for later analysis (maybe for the final) and is the proportion of non-white victims by state
sfp <- sfp %>%
group_by(state) %>%
mutate(Non_White_prop =  sum(race != "W")/n())
#This line just drops all non grouped by state data from this version of the dataframe
By_State <- subset(sfp, select= -c(name, id, age, latitude, longitude, city, manner_of_death, gender, armed, race, signs_of_mental_illness, flee, threat_level, body_camera, date, is_geocoding_exact))
rfp <- fp %>%
group_by(regions) %>%
mutate(rgbcp =  sum(body_camera==TRUE)/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(gen.p =  sum(gender=="M")/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(smi.p =  sum(signs_of_mental_illness==TRUE)/n())
rfp <- rfp %>%
group_by(regions) %>%
mutate(flee.p =  sum(flee=="fleeing")/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(att.p =  sum(threat_level== "attack")/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(armed.p =  sum(armed != "unarmed")/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(MoD.p =  sum(manner_of_death == "shot")/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(age.avg =  sum(age)/n())
rfp <- sfp %>%
group_by(regions) %>%
mutate(Non_White_prop =  sum(race != "W")/n())
By_Region <- subset(sfp, select= -c(name, id, age, latitude, longitude, city, manner_of_death, gender, armed, race, signs_of_mental_illness, flee, threat_level, body_camera, regions, date, is_geocoding_exact))
#Just some tests on the new sub dataset
print("By_State:")
summary(By_State)
print("By Region:")
summary(By_Region)
head(By_State)
summary(By_State)
#Normality check of proportions of body cameras being on by state
qqnorm(By_State$stbcp)
#Seems Normal
#a bar graph showing number of fatal police shootings AND proportions of body cameras being on by region (too many states to show on a bar graph like this)
ggplot(fp, aes(x = regions, y = frequency(regions), color=body_camera)) + geom_bar(stat = "identity")+ labs(x = "State", y="Number of Incidents", title = "Regional Police Shootings Colored by Body Camera Proportions")
#Scatter Plot of Body Camera Proportion by State
ggplot(By_State, aes(x=state, y= stbcp, label=state)) + geom_point(shape=6, color="violet")+ labs(x = "State", y="Body Camera Proportion", title = "Body Camera On Proportion By US State") + geom_text(hjust=1, vjust=-0.6)
mean(By_State$stbcp)
test<- By_State
cat3 <- test %>% mutate(proportion=cut(stbcp, breaks=c(0, 0.10, 0.2, 0.3, Inf),labels = c("low", "medium", "high", "very high")))
summary(cat3$stbcp)
cat3$state <- as.factor(cat3$state)
cat3$stbcp <- as.factor(cat3$stbcp)
contable= table(cat3$state, cat3$stbcp)
#print(contable)
chisq.test(contable)
=======
# korean-fried-chicken-wing pricing
kfcw <- data.frame(wing=c(-5,10,15,20,40,0,0,0,0,3,7,12,20), drum=c(0,0,0,0,0,3,5,10,15,2,4,6,9), price=c(6.69,12.99,17.99,23.99,45.99,6.69,10.99,19.99,29.99,7.99,16.99,27.99,43.99) )
xkabledply(kfcw)
# str(kfcw)
# summary(kfcw)
xkablesummary(kfcw) # better display than the line above
kfcw[1,1]=5  # equal sign "=" and assignment operator "<-" are interchangeable in R
# structure of the data frame kfcw
# str(kfcw)
# summary(kfcw)
xkablesummary(kfcw) # better display than the line above
loadPkg("corrplot")
corrmatrix = cor(kfcw)  # more detailed pair-wise correlation test can be obtained from cor.test(kfcw$wing,kfcw$price) etc
corrplot.mixed(corrmatrix,
title="Correlation Matrix for Chicken Meal Price",
mar=c(0,0,1,0) # fixes the position of title
)
qqnorm(kfcw$price, main = "Price Q-Q Plot", ylab="Price Quantiles ($)")
qqline(kfcw$price)
qqnorm(kfcw$wing, main = "Wing Q-Q Plot", ylab="Wing-count Quantiles")
qqline(kfcw$wing)
qqnorm(kfcw$drum, main = "Drum Q-Q Plot", ylab="Drum-count Quantiles")
qqline(kfcw$drum)
# We will learn to use the more powerful ggplot soon, instead of this generic boxplot function
boxplot(kfcw, col=c("red","blue","green"), ylab="count or price($)", main="Boxplots for the three variables")
axis(side = 4)
# We will learn to use the more powerful ggplot soon, instead of this generic hist function for histograms
barcolors = c("green", "violet", "orange", "blue", "pink", "red", "yellow", "cyan")
hist(kfcw$price, main = "Histogram for Price distribution", xlab="Price ($)", col=barcolors, breaks = 10)
hist(kfcw$wing, main = "Histogram for Wing-count", xlab="Wing Count", col=barcolors, breaks = 6)
hist(kfcw$drum, main = "Histogram for Drum-count", xlab="Drum Count", col=barcolors, breaks = 6)
priceshapiro = shapiro.test(kfcw$price)
wingshapiro = shapiro.test(kfcw$wing)
drumshapiro = shapiro.test(kfcw$drum)
# build a simple linear model (least square fit) of price as a function of everything else.
chicklm = lm(price ~ ., data=kfcw)
# summary(chicklm)
xkabledply(chicklm, title = "Summary of linear model for Chicken Meals")
coeffconfint = confint.lm(chicklm)
# coeffconfint
xkabledply(coeffconfint, title = "Coefficient Confidence Intervals (CI) at 95%") # display better than the line above
loadPkg("faraway") # faraway library is one of them has a vif function
# VIF check the collinearity issues between different variables/features in a (linear) model
# vif(chicklm)
xkablevif(chicklm, title="Chicken Model VIFs")  # better display than the line above
# unloadPkg("faraway")
loadPkg("plot3D")
# reference from http://www.sthda.com/english/wiki/impressive-package-for-3d-and-4d-graph-r-software-and-data-visualization
# x, y, z variables
x <- kfcw$wing
y <- kfcw$drum
z <- kfcw$price
# Compute the linear regression (z = ax + by + d)
# chicklm <- lm(z ~ x + y)
# predict values on regular xy grid
grid.lines = 20
x.pred <- seq(min(x), max(x), length.out = grid.lines)
y.pred <- seq(min(y), max(y), length.out = grid.lines)
xy <- expand.grid( wing = x.pred, drum =y.pred)
z.pred <- matrix(predict.lm(chicklm, newdata = xy), nrow = grid.lines, ncol = grid.lines)
# fitted points for droplines to surface
fitpoints <- predict.lm(chicklm)
# scatter plot with regression plane
scatter3D(x, y, z, pch = 18, cex = 2, theta = 5, phi = 20, ticktype = "detailed", xlab = "wing", ylab = "drum", zlab = "price",  surf = list(x = x.pred, y = y.pred, z = z.pred, facets = NA, fit = fitpoints), main = "Chicken Price Analysis")
kfcw$fitval = chicklm$fitted.values
kfcw$residuals = chicklm$residuals
# kfcw
xkabledply(kfcw, title = "Data values and residuals") # better display than the line above
kfcw$res_2_p = chicklm$residuals/kfcw$price*100
# kfcw
xkabledply(kfcw, title = "Revised Data values and residuals") # better display than the line above
mean(fp$age, na.rm= TRUE)
median(fp$age)
load("/Users/coramartin/Desktop/F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0/Latinobarometro_2020_Eng_Rdata_v1_0.rdata")
Latinobarometro = data.frame(read.csv('/Users/coramartin/Desktop/F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0/Latinobarometro_2020_Eng_Rdata_v1_0.rdata'))
Latinobarometro = data.frame(read.csv('/Users/coramartin/Desktop/F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0/Latinobarometro_2020_Eng_Rdata_v1_0.rdata'))
Latinobarometro = data.frame(read.csv('/Users/coramartin/Desktop/F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0/Latinobarometro_2020_Eng_Rdata_v1_0.rdata'))
str(Latinobarometro)
write.csv(Latinobarometro, "Path to export the DataFrame\\F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0.csv", row.names = FALSE)
write.csv(Latinobarometro, "Path to export the DataFrame\\F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0.csv", row.names = TRUE)
write.csv(Latinobarometro, "'Users/coramartin/Desktop/F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0.csv", row.names = TRUE)
write.csv(Latinobarometro, "Users/coramartin/Desktop/F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0.csv", row.names = TRUE)
write.csv(Latinobarometro, 'Users/coramartin/Desktop/F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0.csv', row.names = FALSE)
Latinobarometro = data.frame(read.csv('/Users/coramartin/Desktop/F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0/Latinobarometro_2020_Eng_Rdata_v1_0.rdata'))
write.csv(Latinobarometro, 'Users/coramartin/Desktop/F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0.csv', row.names = FALSE)
Latinobarometro = data.frame(read.csv('/Users/coramartin/Desktop/F00011657-Latinobarometro_2020_Esp_R_Rdata_v1_0/Latinobarometro_2020_Eng_Rdata_v1_0.rdata'))
write.csv(Latinobarometro, 'Users/coramartin/Desktop/', row.names = FALSE)
>>>>>>> Stashed changes
