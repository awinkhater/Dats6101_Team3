bike_final = bike16
bike_final$Season = factor(bike16$Season)
bike_final$Holiday = factor(bike16$Holiday)
bike_final$Day = factor(bike16$Day)
bike_final$Workday = factor(bike16$Workday)
bike_final$Weather = factor(bike16$Weather)
str(bike_final)
loadPkg("lattice") # lattice and ggplot2 combined allow us to use the "pairs" function below
pairs(bike_final)
# unloadPkg("lattice")
b16nums <- unlist(lapply(bike16, is.numeric), use.names = FALSE)
corrMatrix(b16nums)
library(corrplot)
b16nums <- unlist(lapply(bike16, is.numeric), use.names = FALSE)
corrMatrix(b16nums)
library(corrplot)
b16nums <- unlist(lapply(bike16, is.numeric), use.names = FALSE)
corrplot(b16nums)
library(corrplot)
b16nums <- unlist(lapply(bike16, is.numeric), use.names = FALSE)
corrplot(bike16)
library(corrplot)
b16nums <- unlist(lapply(bike16, is.numeric), use.names = FALSE)
corrplot(bike)
library(corrplot)
b16nums <- unlist(lapply(bike16, is.numeric), use.names = FALSE)
bc=cor(bike16)
corrplot(bc, method= 'number')
library(corrplot)
b16nums <- unlist(lapply(bike16, is.numeric), use.names = FALSE)
bc=cor(bike16)
corrplot(bc, method= 'color')
library(corrplot)
BC <- subset(bike16, select = -c(Hour) )
bc=cor(bike16)
corrplot(bc, method= 'color')
library(corrplot)
BC <- subset(bike16, select = -c(Hour) )
bc=cor(BC)
corrplot(bc, method= 'color')
library(corrplot)
BC <- subset(bike16, select = -c(Hour) )
bc=cor(BC)
corrplot(bc, method= 'number')
lm1 <- model(bike16, Total.Users ~ TFF)
lm1 <- lm(Total.Users ~ TFF, data=bike16)
lm1 <- lm(Total.Users ~ TFF, data=bike16)
summary(lm1)
library(corrplot)
BC <- subset(bike16, select = -c(Hour) )
bc=cor(BC)
corrplot(bc, method= 'number')
lm2 <- lm(Total.Users~ (TFF+Weather), data=bike16)
lm2 <- lm(Total.Users~ (TFF+Weather), data=bike16)
summary(lm2)
lm2 <- lm(Total.Users~ (TFF+Weather), data=bike16)
summary(lm2)
car::vif(lm2 )
lm3 <- lm(Total.Users~ (TFF+Weather+ Season), data=bike16)
summary(lm3)
car::vif(lm3 )
confint(bike16$lm3)
confint(lm3)
#install.packages("rlang")
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
bikeorig<-read.csv("bikedata.csv")
bike<- subset(bikeorig, select = -c(Date,Casual.Users, Registered.Users) )
# Syntax rename with condition
colnames(bike)[colnames(bike) == "Day.of.the.week"] ="day.w"
colnames(bike)[colnames(bike) == "Weather.Type"] ="Weather"
colnames(bike)[colnames(bike) == "Temperature.F"] ="Temp.F"
colnames(bike)[colnames(bike) == "Temperature.Feels.F"] ="TFF"
colnames(bike)[colnames(bike) == "Wind.Speed"] ="Wind"
colnames(bike)[colnames(bike) == "Working.Day"] ="Workday "
summary(bike)
str(bike)
nrow(bike)
bike16 <- subset(bike, Hour==16)
nrow(bike16)
bike_final = bike16
bike_final$Season = factor(bike16$Season)
bike_final$Holiday = factor(bike16$Holiday)
bike_final$Day = factor(bike16$Day)
bike_final$Workday = factor(bike16$Workday)
bike_final$Weather = factor(bike16$Weather)
str(bike_final)
loadPkg("lattice") # lattice and ggplot2 combined allow us to use the "pairs" function below
pairs(bike_final)
# unloadPkg("lattice")
library(corrplot)
BC <- subset(bike16, select = -c(Hour) )
bc=cor(BC)
corrplot(bc, method= 'number')
lm1 <- lm(Total.Users ~ TFF, data=bike16)
summary(lm1)
lm2 <- lm(Total.Users~ (TFF+Weather), data=bike16)
summary(lm2)
car::vif(lm2 )
lm3 <- lm(Total.Users~ (TFF+Weather+ Season), data=bike16)
summary(lm3)
car::vif(lm3 )
confint(lm3)
#install.packages("rlang")
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
bikeorig<-read.csv("bikedata.csv")
bike<- subset(bikeorig, select = -c(Date,Casual.Users, Registered.Users) )
# Syntax rename with condition
colnames(bike)[colnames(bike) == "Day.of.the.week"] ="day.w"
colnames(bike)[colnames(bike) == "Weather.Type"] ="Weather"
colnames(bike)[colnames(bike) == "Temperature.F"] ="Temp.F"
colnames(bike)[colnames(bike) == "Temperature.Feels.F"] ="TFF"
colnames(bike)[colnames(bike) == "Wind.Speed"] ="Wind"
colnames(bike)[colnames(bike) == "Working.Day"] ="Workday "
summary(bike)
str(bike)
nrow(bike)
bike16 <- subset(bike, Hour==16)
nrow(bike16)
bike_final = bike16
bike_final$Season = factor(bike16$Season)
bike_final$Holiday = factor(bike16$Holiday)
bike_final$Day = factor(bike16$Day)
bike_final$Workday = factor(bike16$Workday)
bike_final$Weather = factor(bike16$Weather)
str(bike_final)
bikeorig<-read.csv("bikedata.csv")
bike<- subset(bikeorig, select = -c(Date,Casual.Users, Registered.Users) )
str(bikeorig)
# Syntax rename with condition
colnames(bike)[colnames(bike) == "Day.of.the.week"] ="day.w"
colnames(bike)[colnames(bike) == "Weather.Type"] ="Weather"
colnames(bike)[colnames(bike) == "Temperature.F"] ="Temp.F"
colnames(bike)[colnames(bike) == "Temperature.Feels.F"] ="TFF"
colnames(bike)[colnames(bike) == "Wind.Speed"] ="Wind"
colnames(bike)[colnames(bike) == "Working.Day"] ="Workday "
summary(bike)
str(bike)
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course.
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
library(ezids)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
loadPkg("ggplot2")
# Admit <- data.frame(read.csv("LogRegAdmit.csv"))
Admit <- api_rfit("gradAdmit")
head(Admit)
summary(Admit)
str(Admit)
xkablesummary(Admit)
# find  sd for all columns, using sapply
varSD = sapply(Admit, sd)
varSD
xkabledply(as.table(varSD), title = "The sd for each variable in Admit", wide = TRUE)
admitranktable = xtabs(~ admit + rank, data = Admit)
admitranktable
Admit$admit <- factor(Admit$admit)
str(Admit)
Admit$rank <- factor(Admit$rank)
#str(Admit)
admitLogit <- glm(admit ~ gre + gpa + rank, data = Admit, binomial(link = "logit") )
summary(admitLogit)
xkabledply(admitLogit, title = paste("Logistic Regression :", format(formula(admitLogit)) ))
p_fitted = admitLogit$fitted.values[1] # this is the model predicated value p-hat for the first data row (not the actual data point p)
# This gives you the predicted values of the data points inside the model.
predict(admitLogit)  # the is from the model, which gives you the value for logit(p) or ln(p/q)
# To get new data points, we can do these
newdata1 <- data.frame(gre = 380, gpa = 3.61, rank = as.factor(3)) # new data frame with 1 row
predict(admitLogit, newdata = newdata1)
# The default option is "link", with gives you the value of the link function,
# in this case, logit(p) or log(p/1-p) value
predict(admitLogit, newdata = newdata1, type = "link") -> pred_link # same as predict(admitLogit, newdata = newdata1)
paste("This is pred_link: ",pred_link)
predict(admitLogit, newdata = newdata1, type = "response") -> pred_response
paste("This is pred_response: ",pred_response)
predict(admitLogit, newdata = newdata1, type = "term") -> pred_term
paste("This is pred_term, which is a vector with three values, plus the y-intercept term, called `attribute`")
pred_term
# attr(pred_term,"constant")
# But this is not "y-value" p that we want to compare to.
# These three things are the same:
# 1. using the response option:
predict(admitLogit, newdata = newdata1, type = "response")
# 2. Using the link function value (default), to calculate the probability p-hat:
1/(1+exp(-predict(admitLogit, newdata = newdata1))) # 1/(1+exp(-predict(admitLogit, newdata = newdata1, type="link")))
# 3. Find the odds-ratio first, then calculate the probability p-hat:
oddsratio = exp( predict(admitLogit, newdata = newdata1, type="link"))
oddsratio / (oddsratio+1)
## CIs using profiled log-likelihood
# confint(admitLogit)
xkabledply( confint(admitLogit), title = "CIs using profiled log-likelihood" )
## CIs using standard errors
# confint.default(admitLogit)
xkabledply( confint.default(admitLogit), title = "CIs using standard errors" )
loadPkg("regclass")
# confusion_matrix(admitLogit)
xkabledply( confusion_matrix(admitLogit), title = "Confusion matrix from Logit Model" )
unloadPkg("regclass")
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(admitLogit, type = "response" )
Admit$prob=prob
h <- roc(admit~prob, data=Admit)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)
# unloadPkg("pROC")
unloadPkg("pROC")
admitNullLogit <- glm(admit ~ 1, data = Admit, family = "binomial")
mcFadden = 1 - logLik(admitLogit)/logLik(admitNullLogit)
mcFadden
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
admitLogitpr2 = pR2(admitLogit)
admitLogitpr2
unloadPkg("pscl")
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
admitLogitHoslem = hoslem.test(Admit$admit, fitted(admitLogit)) # Hosmer and Lemeshow test, a chi-squared test
unloadPkg("ResourceSelection")
admitLogitHoslem
# Have not found a good way to display it.
unloadPkg("pROC")
unloadPkg("aod")
#loadPkg("ggplot2")
library(ggplot2)
# Admit <- data.frame(read.csv("LogRegAdmit.csv"))
Admit <- api_rfit("gradAdmit")
head(Admit)
summary(Admit)
str(Admit)
str(rank)
summary(admitLogit)
knitr::opts_chunk$set(echo = FALSE)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
# knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = FALSE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
always_allow_html = TRUE
#Calling Packages
library(dplyr, quietly = TRUE)
library(ggplot2)
library(plotly)
knitr::opts_chunk$set(echo = FALSE)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
# knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = FALSE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
always_allow_html = TRUE
#Calling Packages
library(dplyr, quietly = TRUE)
library(ggplot2)
library(plotly)
#FINAL PROJECT WORK: ADDING NEW COLUMNS OF DATA
#Not sure if these will correspond to the old df, I am trying and if not, Ill talk to Professor Faruqe
#PLEASE DO NOT ALTER
#This is the state spending on police per capita
By_State$spendpc <- c(477, 1030, 655, 422, 981, 664, 564, 774, 1337, 704, 491, 549, 576, 633, 407, 441, 553, 390, 526, 425, 842, 597, 550, 633, 446, 480, 608, 611, 756, 525, 691, 759, 904, 549, 574, 555, 487, 736, 665, 728, 431, 478, 515, 547, 655, 484, 588, 656, 608, 492, 604, 782 )
#Getting row count and latest incident
nrow(fp)
#FINAL PROJECT WORK: ADDING NEW COLUMNS OF DATA
#Not sure if these will correspond to the old df, I am trying and if not, Ill talk to Professor Faruqe
#PLEASE DO NOT ALTER
#This is the state spending on police per capita
spendpc <- c(477, 1030, 655, 422, 981, 664, 564, 774, 1337, 704, 491, 549, 576, 633, 407, 441, 553, 390, 526, 425, 842, 597, 550, 633, 446, 480, 608, 611, 756, 525, 691, 759, 904, 549, 574, 555, 487, 736, 665, 728, 431, 478, 515, 547, 655, 484, 588, 656, 608, 492, 604, 782 )
#Want a for loop to assign for each state
FDS <- data.frame(By_State)
FDS$spendpc <- rep(c(1, 7574))
#FINAL PROJECT WORK: ADDING NEW COLUMNS OF DATA
#Not sure if these will correspond to the old df, I am trying and if not, Ill talk to Professor Faruqe
#PLEASE DO NOT ALTER
#This is the state spending on police per capita
vspc <- c(477, 1030, 655, 422, 981, 664, 564, 774, 1337, 704, 491, 549, 576, 633, 407, 441, 553, 390, 526, 425, 842, 597, 550, 633, 446, 480, 608, 611, 756, 525, 691, 759, 904, 549, 574, 555, 487, 736, 665, 728, 431, 478, 515, 547, 655, 484, 588, 656, 608, 492, 604, 782 )
#Want a for loop to assign for each state
FDS <- data.frame(By_State)
FDS$spendpc <- rep(c(1, 7574))
for(i in nrow(FDS)) {
if (i$state == 'AL') {
i$state <- vspc[0]
} else if (i$state == 'AK') {
i$state <- vspc[1]}
}
#FINAL PROJECT WORK: ADDING NEW COLUMNS OF DATA
#Not sure if these will correspond to the old df, I am trying and if not, Ill talk to Professor Faruqe
#PLEASE DO NOT ALTER
#This is the state spending on police per capita
vspc <- c(477, 1030, 655, 422, 981, 664, 564, 774, 1337, 704, 491, 549, 576, 633, 407, 441, 553, 390, 526, 425, 842, 597, 550, 633, 446, 480, 608, 611, 756, 525, 691, 759, 904, 549, 574, 555, 487, 736, 665, 728, 431, 478, 515, 547, 655, 484, 588, 656, 608, 492, 604, 782 )
#States that require Body Cameras be worn in interactions with the public as of jan 1 2021:
#Maryland, New Jersey, New Mexico, and South Carolina
#Want a for loop to assign for each state
FDS <- data.frame(By_State)
FDS$spendpc <- rep(c(1, 7574))
print(vspc[50])
#FINAL PROJECT WORK: ADDING NEW COLUMNS OF DATA
#Not sure if these will correspond to the old df, I am trying and if not, Ill talk to Professor Faruqe
#PLEASE DO NOT ALTER
#This is the state spending on police per capita
vspc <- c(477, 1030, 655, 422, 981, 664, 564, 774, 1337, 704, 491, 549, 576, 633, 407, 441, 553, 390, 526, 425, 842, 597, 550, 633, 446, 480, 608, 611, 756, 525, 691, 759, 904, 549, 574, 555, 487, 736, 665, 728, 431, 478, 515, 547, 655, 484, 588, 656, 608, 492, 604, 782 )
#States that require Body Cameras be worn in interactions with the public as of jan 1 2021:
#Maryland, New Jersey, New Mexico, and South Carolina
#Want a for loop to assign for each state
FDS <- data.frame(By_State)
FDS$spendpc <- rep(c(1, 7574))
print(vspc[0])
#FINAL PROJECT WORK: ADDING NEW COLUMNS OF DATA
#Not sure if these will correspond to the old df, I am trying and if not, Ill talk to Professor Faruqe
#PLEASE DO NOT ALTER
#This is the state spending on police per capita
vspc <- c(477, 1030, 655, 422, 981, 664, 564, 774, 1337, 704, 491, 549, 576, 633, 407, 441, 553, 390, 526, 425, 842, 597, 550, 633, 446, 480, 608, 611, 756, 525, 691, 759, 904, 549, 574, 555, 487, 736, 665, 728, 431, 478, 515, 547, 655, 484, 588, 656, 608, 492, 604, 782 )
#States that require Body Cameras be worn in interactions with the public as of jan 1 2021:
#Maryland, New Jersey, New Mexico, and South Carolina
#Want a for loop to assign for each state
FDS <- data.frame(By_State)
FDS$spendpc <- rep(c(1, 7574))
print(vspc[1])
#FINAL PROJECT WORK: ADDING NEW COLUMNS OF DATA
#Not sure if these will correspond to the old df, I am trying and if not, Ill talk to Professor Faruqe
#PLEASE DO NOT ALTER
#This is the state spending on police per capita
vspc <- c(477, 1030, 655, 422, 981, 664, 564, 774, 1337, 704, 491, 549, 576, 633, 407, 441, 553, 390, 526, 425, 842, 597, 550, 633, 446, 480, 608, 611, 756, 525, 691, 759, 904, 549, 574, 555, 487, 736, 665, 728, 431, 478, 515, 547, 655, 484, 588, 656, 608, 492, 604, 782 )
#States that require Body Cameras be worn in interactions with the public as of jan 1 2021:
#Maryland, New Jersey, New Mexico, and South Carolina
#Want a for loop to assign for each state
FDS <- data.frame(By_State)
FDS$spendpc <- rep(c(1, 7574))
print(vspc[51])
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "markup", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
library(ggplot2)
df<- read.csv("LogRegAdmit.csv")
knitr::opts_chunk$set(echo = FALSE)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
# knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = FALSE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
always_allow_html = TRUE
#Calling Packages
library(dplyr, quietly = TRUE)
library(ggplot2)
library(plotly)
library(ggthemes)
library(tidyverse)
library(forecast)
library(ggalluvial)
#Reading the data set
fp<- data.frame(read.csv("FPS22.csv"))
#Cleaning null values from data set
fp <- (fp %>% filter(race != ''))
fp <- (fp %>% filter(gender != ''))
camera_no <- fp %>% filter(body_camera != TRUE)
camera_yes <- fp %>% filter(body_camera != FALSE)
fp1 <- na.omit(fp)
#Getting row count and latest incident
nrow(fp)
#Creating new columns from existing columns
fp$date <- as.Date(fp$date, "%m/%d/%Y")
fp$date <- as.Date(fp$date, "%m/%d/%Y")
fp$month <- format(fp$date, format = "%m")
fp$year <- format(fp$date, format = "%Y")
fp$month <- format(fp$date, format = "%m")
fp$year <- format(fp$date, format = "%Y")
mean(fp1$age, na.rm= TRUE)
median(fp1$age)
ggplot(fp, aes(x=age)) + geom_histogram( binwidth =0.6,aes(fill = ..count..))+scale_fill_gradient('Count',low='blue',high='red') + labs(x = "Age of Victim", y="Number of Deaths", title = "Age Frequency Histogram")
ggplot(fp, aes(x=race,fill=race, color=race)) + geom_histogram(stat="count") + labs(x = "Race: Unknown, Asian, Black, Hispanic, Native, Other, White", y="Number of Deaths", title = "Race Frequency Histogram")
ggplot(fp, aes(x=gender, fill=gender, color=gender)) + geom_histogram(stat="count") + labs(x = "Gender", y="Number of Deaths", title = "Gender Frequency Histogram")
ggplot(fp, aes(x= manner_of_death, fill=manner_of_death, color=manner_of_death)) + geom_histogram(stat="count") + labs(x = "Manner of Death", y="Number of Deaths", title = "Manner of Death Frequency Histogram")
ggplot(fp, aes(x=threat_level, fill=threat_level, color=threat_level)) + geom_histogram(stat="count") + labs(x = "Threat Level", y="Number of Deaths", title = "Threat Level Frequency Histogram")
police_sr <- fp %>%
filter(!race == "") %>%
group_by(state, race) %>%
summarise(deaths = n())
#Spreading the data to get deaths by race
spread_sr <- spread(police_sr, race, deaths)
#Getting the total number of deaths per state
spread_sr$Total <- rowSums(spread_sr[,-1], na.rm = TRUE)
#Check the results if needed
# head(spread_sr)
#Data setup for hovering on the map
sr_data <- spread_sr
sr_data$hover <- with(sr_data, paste("Asian", A, '<br>',
"Black",B,'<br>',
"Hispanic",H,'<br>',
"Native American",N,'<br>',
"Other",O,'<br>',
"White",W,'<br>',
"Total Deaths", `Total`))
#Map specifications
graph <- list(
scope = 'usa',
projection = list(type = 'albers usa'),
showlakes = TRUE,
lakecolor = toRGB('white')
)
#Plotting the graph
plot_ly(spread_sr, z = spread_sr$Total, text = sr_data$hover, locations = sr_data$state, type = 'choropleth',
locationmode = 'USA-states', color = spread_sr$Total, colors = 'Reds',
colorbar = list(title = "Counts ")) %>%
layout(title = 'Number of people shot dead by race per State<br>(Hover for breakdown by race)', geo = graph)
#Box plots
ggplot (fp,aes(x=race, y=age)) +
geom_boxplot(aes(color = race)) +
#Axes labels and titles
labs(x = "Race of Victim", y = "Age of Victim",
title = "Distribution of Victims' Age across Race") +
scale_x_discrete(labels=c('White',
'Other',
'Native American',
'Hispanic',
'Black',
'Asian')) +
coord_flip() +
theme_bw() +
theme(legend.position = "none")
#Age against signs of mental illness
ggplot(fp, aes(x=signs_of_mental_illness, y=age, fill=signs_of_mental_illness)) + geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) + labs(x = "Sign of Mental Illness", y="Age", title = "Status of Mental Wellbeing during Fatal Shooting by Age of Victim")
#Filtering the data by race and gender
data_by_rg <- fp %>%
filter(race != "") %>%
filter(gender != "") %>%
group_by(race, gender) %>%
summarize(No_of_deaths = n())
#Plotting Data
ggplot(data_by_rg, aes(x = race, y = No_of_deaths, fill = gender)) +
geom_bar(stat = "identity",position = "dodge") +
labs (x = 'Race', y = 'Number of Deaths') +
ggtitle('Deaths by Race and Gender') +
scale_x_discrete(labels=c('Asian',
'Black',
'Hispanic',
'Native American',
'Other',
'White')) +
theme_few()
# Finding the top 5 arms used by suspects
top_5_arms <- fp %>%
group_by(armed) %>%
summarise(num_arms = n()) %>%
arrange(desc(num_arms)) %>%
head(5)
#Filtering the data by top 5 arms found
race_armed_data <- fp %>%
filter(race != '') %>%
mutate(armed_mod = ifelse(armed %in% c('gun', 'knife', 'unarmed', 'vehicle', 'undetermined'), as.character(armed), 'Other')) %>%
group_by(race, armed_mod) %>%
summarise(Deaths = n())
# Spreading the data
race_armed_data_spr <- race_armed_data %>%
spread(armed_mod, Deaths)
#Replacing missing values with 0
race_armed_data_spr[is.na(race_armed_data_spr)] <- 0
#Printing the data
summary_table <- cbind(as.data.frame(race_armed_data_spr[,1]), as.data.frame(round(race_armed_data_spr[,-1]/rowSums(race_armed_data_spr[,-1])*100, 2)))
#Renaming the race values
levels(summary_table$race) <- c("", "Asian", "Black", "Hispanic", "Native American", "Other", "White")
#Print the table
print(summary_table)
#Plotting the above table in a stacked bar
ggplot(race_armed_data, aes(x = race, y = Deaths, fill = armed_mod)) +
geom_bar(stat = "identity",position = "dodge") +
labs (x = 'Race', y = 'Number of Deaths') +
ggtitle('Whether Victims were Armed by Race') +
scale_x_discrete(labels=c('Asian',
'Black',
'Hispanic',
'Native American',
'Other',
'White')) +
theme_few()
#Filtering the data and summarizing it
